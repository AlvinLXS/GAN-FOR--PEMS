{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.csv','r') as csvfile:\n",
    "    reader=csv.reader(csvfile)\n",
    "    rows=[row[1] for row in reader]\n",
    "# fig=plt.figure(figsize=(20,10),dpi=1000)\n",
    "# ll=plt.plot(rows[0:1000],linewidth=1.2,color='b')\n",
    "# plt.show()\n",
    "# fig.savefig('10000.png')\n",
    "# print(len(rows))\n",
    "LENGTH=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x):\n",
    "    \"\"\"\n",
    "    计算每一组数据平均值和方差\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return [[np.mean(data), np.std(data)] for data in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########搭建网络\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2], name=\"feature\")  # [mean，std] -》 D\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name=\"label\")\n",
    "in_size = LENGTH\n",
    "out_size = LENGTH\n",
    "###################################### G  网络结构\n",
    "# 第一层\n",
    "z = tf.placeholder(tf.float32, shape=[None, LENGTH], name=\"noise\")  # 随机值噪音\n",
    "Weights = tf.Variable(tf.random_normal([in_size, 32]))\n",
    "biases = tf.Variable(tf.zeros([1, 32]) + 0.1)\n",
    "G_output = tf.matmul(z, Weights) + biases\n",
    "G_output = tf.nn.relu(G_output)\n",
    "# 第二层\n",
    "Weights2 = tf.Variable(tf.random_normal([32, 32]))\n",
    "biases2 = tf.Variable(tf.zeros([1, 32]) + 0.1)\n",
    "G_output2 = tf.matmul(G_output, Weights2) + biases2\n",
    "G_output2 = tf.nn.sigmoid(G_output2)\n",
    "# 第三层\n",
    "Weights3 = tf.Variable(tf.random_normal([32, out_size]))\n",
    "biases3 = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "\n",
    "G_output3 = tf.matmul(G_output2, Weights3) + biases3\n",
    "\n",
    "G_PARAMS = [Weights, biases, Weights2, biases2, Weights3, biases3]  # G的参数\n",
    "\n",
    "###################################### D 网络结构(预训练的D)\n",
    "# 第一层\n",
    "\n",
    "dWeights = tf.Variable(tf.random_normal([2, 32]), name=\"D_W\")\n",
    "dbiases = tf.Variable(tf.zeros([1, 32]) + 0.1, name=\"D_b\")\n",
    "D_output = tf.matmul(x, dWeights) + dbiases\n",
    "D_output = tf.nn.relu(D_output)\n",
    "# 第二层\n",
    "dWeights2 = tf.Variable(tf.random_normal([32, 32]), name=\"D_W2\")\n",
    "dbiases2 = tf.Variable(tf.zeros([1, 32]) + 0.1, name=\"D_b2\")   \n",
    "D_output2 = tf.matmul(D_output, dWeights2) + dbiases2\n",
    "D_output2 = tf.nn.sigmoid(D_output2)\n",
    "\n",
    "# 第三层\n",
    "dWeights3 = tf.Variable(tf.random_normal([32, 1]), name=\"D_W3\")\n",
    "dbiases3 = tf.Variable(tf.zeros([1, 1]) + 0.1, name=\"D_b3\")\n",
    "D_output3_ = tf.matmul(D_output2, dWeights3) + dbiases3\n",
    "D_output3 = tf.nn.sigmoid(D_output3_)\n",
    "\n",
    "D_PARAMS = [dWeights, dbiases,\n",
    "            dWeights2, dbiases2,\n",
    "            dWeights3, dbiases3]\n",
    "\n",
    "##################################### GAN的结构\n",
    "\n",
    "# 先求出G_output3的各行平均值和方差\n",
    "MEAN = tf.reduce_mean(G_output3, 1)  # 行向量\n",
    "MEAN_T = tf.transpose(tf.expand_dims(MEAN, 0))  # 转置\n",
    "STD = tf.sqrt(tf.reduce_mean(tf.square(G_output3 - MEAN_T), 1))\n",
    "DATA = tf.concat([MEAN_T,tf.transpose(tf.expand_dims(STD, 0))],1)\n",
    "\n",
    "# GAN中的D\n",
    "GAN_Weights = tf.Variable(tf.random_normal([2, 32]), name=\"GAN_W\")\n",
    "GAN_biases = tf.Variable(tf.zeros([1, 32]) + 0.1, name=\"GAN_b\")\n",
    "GAN_output = tf.matmul(DATA, GAN_Weights) + GAN_biases\n",
    "GAN_output = tf.nn.relu(GAN_output)\n",
    "# 第二层\n",
    "GAN_Weights2 = tf.Variable(tf.random_normal([32, 32]), name=\"GAN_W2\")\n",
    "GAN_biases2 = tf.Variable(tf.zeros([1, 32]) + 0.1, name=\"GAN_b2\")\n",
    "GAN_output2 = tf.matmul(GAN_output, GAN_Weights2) + GAN_biases2\n",
    "GAN_output2 = tf.nn.sigmoid(GAN_output2)\n",
    "\n",
    "# 第三层\n",
    "GAN_Weights3 = tf.Variable(tf.random_normal([32, 1]), name=\"GAN_W3\")\n",
    "GAN_biases3 = tf.Variable(tf.zeros([1, 1]) + 0.1, name=\"GAN_b3\")\n",
    "GAN_output3_ = tf.matmul(GAN_output2, GAN_Weights3) + GAN_biases3\n",
    "GAN_output3 = tf.nn.sigmoid(GAN_output3_)\n",
    "\n",
    "GAN_D_PARAMS = [GAN_Weights, GAN_biases,\n",
    "                GAN_Weights2, GAN_biases2,\n",
    "                GAN_Weights3, GAN_biases3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### 定义损失函数\n",
    "d_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=D_output3_, logits=y))  # 二分类交叉熵\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=GAN_output3_, logits=y))  # GAN二分类交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################### 定义优化器\n",
    "d_optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(\n",
    "    d_loss,\n",
    "    global_step=tf.Variable(0),\n",
    "    var_list=D_PARAMS\n",
    ")\n",
    "\n",
    "g_optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(\n",
    "    g_loss,\n",
    "    global_step=tf.Variable(0),\n",
    "    var_list=G_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train GAN....\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-34f8700a6bd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# 使用G生成一批样本:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mreal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             generate = sess.run(G_output3, feed_dict={\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_data' is not defined"
     ]
    }
   ],
   "source": [
    "d_loss_history = []\n",
    "g_loss_history = []\n",
    "epoch = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # GAN博弈开始\n",
    "    print('train GAN....')\n",
    "    for step in range(epoch):\n",
    "        # 先进行GAN中的D的训练，即对生成样本的判断\n",
    "        for _ in range(100):\n",
    "            # 使用G生成一批样本:\n",
    "            real = sample_data(100,length=LENGTH)\n",
    "            noise = random_data(100,length=LENGTH)\n",
    "            generate = sess.run(G_output3, feed_dict={z: noise})  # 生成样本\n",
    "            X = list(real) + list(generate)  \n",
    "            X = preprocess_data(X)\n",
    "            Y = [[1] for _ in range(len(real))] + [[0] for _ in range(len(generate))]\n",
    "            d_loss_value, _ = sess.run([d_loss, d_optimizer], feed_dict={x: X,y: Y})# 训练判别网络\n",
    "            d_loss_history.append(d_loss_value)\n",
    "        # 将参数移动过去GAN中的判别网络\n",
    "        dp_value = sess.run(D_PARAMS)\n",
    "        for i, v in enumerate(GAN_D_PARAMS):\n",
    "            sess.run(v.assign(dp_value[i]))\n",
    "\n",
    "        for _ in range(100):\n",
    "            noise = random_data(100,length=LENGTH)\n",
    "            g_loss_value, _ = sess.run([g_loss, g_optimizer], feed_dict={\n",
    "                z: noise,\n",
    "                y: [[1] for _ in range(len(noise))]  # 混肴为目标,不需要加入x，我们只是借助G，并不需要训练G\n",
    "            })  # 调整G，让GAN的误差减少\n",
    "            g_loss_history.append(g_loss_value)\n",
    "        if step % 20 == 0 or step+1 == epoch:\n",
    "            noise = random_data(1,length=LENGTH)\n",
    "            generate = sess.run(G_output3, feed_dict={\n",
    "                z: noise\n",
    "            })\n",
    "            print(\"[%4d] GAN-d-loss: %.12f  GAN-g-loss: %.12f   generate-mean: %.4f   generate-std: %.4f\" % (step,\n",
    "                            d_loss_value, g_loss_value,generate.mean() ,generate.std() ))\n",
    "            \n",
    "            \n",
    "    print(\"train finish...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
